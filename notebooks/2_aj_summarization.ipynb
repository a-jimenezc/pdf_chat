{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def get_topics_from_pdf(file, num_topics, words_per_topic):\n",
    "    \"\"\"\n",
    "    Uses LDA algoritm for topic discovery\n",
    "    Returns: list of num_topics lists with relevant words for each topic (nested list).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    loader = PdfReader(file)\n",
    "\n",
    "    documents= []\n",
    "    for page in loader.pages:\n",
    "        documents.append(page.extract_text())\n",
    "\n",
    "    # Preprocess the documents\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words(['english','spanish']))\n",
    "\n",
    "    def preprocess(text):\n",
    "        result = []\n",
    "        for token in simple_preprocess(text, deacc=True):\n",
    "            if token not in stop_words and len(token) > 3:\n",
    "                result.append(token)\n",
    "        return result\n",
    "\n",
    "    processed_documents = [preprocess(doc) for doc in documents]\n",
    "\n",
    "    # Create a dictionary and a corpus\n",
    "    dictionary = corpora.Dictionary(processed_documents)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
    "\n",
    "    # Build the LDA model\n",
    "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)\n",
    "\n",
    "    # Print the topics and their corresponding words\n",
    "    topics = lda_model.print_topics(num_words=words_per_topic)\n",
    "    topics_ls = []\n",
    "    for topic in topics:\n",
    "        words = topic[1].split(\"+\")\n",
    "        topic_words = [word.split(\"*\")[1].replace('\"', '').strip() for word in words]\n",
    "        topics_ls.append(topic_words)\n",
    "        \n",
    "    return topics_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton_glfk00f\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src import get_topics_from_pdf\n",
    "file = \"Philip Kotler, Gary Armstrong - Marketing_ Versión latinoamerica (2007).pdf\"\n",
    "file = \"PROGRAMA ANALITICO MÓDULO.pdf\"\n",
    "num_topics = 7\n",
    "words_per_topic = 30\n",
    "\n",
    "list_of_topicwords = get_topics_from_pdf(file, num_topics, words_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton_glfk00f\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marketing', 'brand', 'advertising', 'sales', 'media', 'campaign', 'product', 'company', 'people', 'world', 'indd', 'costs', 'cost', 'percent', 'digital', 'million', 'market', 'social', 'example', 'brands', 'also', 'even', 'year', 'consumers', 'products', 'content', 'time', 'consumer', 'like', 'customer']\n",
      "['price', 'pricing', 'prices', 'product', 'market', 'products', 'company', 'value', 'customers', 'companies', 'consumers', 'business', 'buying', 'indd', 'example', 'many', 'customer', 'competitors', 'consumer', 'even', 'high', 'must', 'marketing', 'based', 'buyers', 'brand', 'strategy', 'costs', 'demand', 'also']\n",
      "['customer', 'sales', 'customers', 'brand', 'product', 'products', 'online', 'marketing', 'consumers', 'company', 'brands', 'store', 'digital', 'service', 'example', 'indd', 'value', 'consumer', 'companies', 'many', 'also', 'retailers', 'media', 'mobile', 'social', 'selling', 'time', 'services', 'stores', 'people']\n",
      "['https', 'accessed', 'marketing', 'september', 'news', 'data', 'business', 'html', 'october', 'january', 'february', 'forbes', 'march', 'blog', 'april', 'world', 'december', 'june', 'research', 'information', 'statistics', 'http', 'brands', 'insights', 'article', 'november', 'global', 'indd', 'amazon', 'market']\n",
      "['global', 'company', 'markets', 'marketing', 'companies', 'market', 'product', 'countries', 'products', 'world', 'indd', 'example', 'country', 'local', 'also', 'many', 'services', 'starbucks', 'india', 'trade', 'must', 'percent', 'international', 'stores', 'customers', 'united', 'home', 'china', 'strategy', 'across']\n",
      "['marketing', 'customer', 'company', 'value', 'market', 'customers', 'business', 'channel', 'product', 'social', 'companies', 'digital', 'indd', 'consumer', 'information', 'research', 'strategy', 'must', 'products', 'data', 'also', 'consumers', 'media', 'objective', 'management', 'strategies', 'needs', 'communication', 'process', 'chapter']\n",
      "['media', 'products', 'company', 'product', 'percent', 'sales', 'million', 'marketing', 'market', 'social', 'indd', 'brand', 'google', 'example', 'instagram', 'brands', 'people', 'year', 'content', 'many', 'facebook', 'also', 'water', 'wise', 'domotics', 'even', 'consumers', 'like', 'companies', 'world']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from pypdf import PdfReader\n",
    "\n",
    "#file = \"Philip Kotler, Gary Armstrong - Marketing_ Versión latinoamerica (2007).pdf\"\n",
    "file = \"Philip Kotler, Gary Armstrong, Sridhar Balasubramanian - Principles of Marketing-Pearson (2023).pdf\"\n",
    "loader = PdfReader(file)\n",
    "\n",
    "documents= []\n",
    "for page in loader.pages:\n",
    "    documents.append(page.extract_text())\n",
    "\n",
    "# Preprocess the documents\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words(['english','spanish']))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in simple_preprocess(text, deacc=True):\n",
    "        if token not in stop_words and len(token) > 3:\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "processed_documents = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary and a corpus\n",
    "dictionary = corpora.Dictionary(processed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
    "\n",
    "# Build the LDA model\n",
    "lda_model = LdaModel(corpus, num_topics=7, id2word=dictionary, passes=15)\n",
    "\n",
    "# Print the topics and their corresponding words\n",
    "topics = lda_model.print_topics(num_words=30)\n",
    "topics_ls = []\n",
    "for topic in topics:\n",
    "    words = topic[1].split(\"+\")\n",
    "    topic_words = [word.split(\"*\")[1].replace('\"', '').strip() for word in words]\n",
    "    print(topic_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton_glfk00f\\miniconda3\\envs\\llm_app_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton_glfk00f\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src import get_topics_from_pdf\n",
    "\n",
    "file = \"Philip Kotler, Gary Armstrong - Marketing_ Versión latinoamerica (2007).pdf\"\n",
    "file = \"PROGRAMA ANALITICO MÓDULO.pdf\"\n",
    "num_topics = 7\n",
    "words_per_topic = 30\n",
    "\n",
    "list_of_topicwords = get_topics_from_pdf(file, num_topics, words_per_topic)\n",
    "string = \"\"\n",
    "for list in list_of_topicwords:\n",
    "    string += str(list) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_lda = \"\"\n",
    "for list in list_of_topicwords:\n",
    "    string_lda += str(list) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['modulo', 'school', 'marketing', 'uagrmbs', 'uagrm', 'business', 'fecha', 'docente', 'bibliografia', 'contenido', 'realizacion', 'desarrollo', 'gestion', 'telefono', 'herramientas', 'santa', 'gral', 'calle', 'empresas', 'academicos', 'maestria', 'solicitudes', 'codigo', 'postgraduantes', 'evaluacion', 'ventas', 'requisitos', 'saavedra', 'siguiente', 'especificacion']\n",
      "['modulo', 'marketing', 'school', 'uagrm', 'docente', 'fecha', 'bibliografia', 'contenido', 'herramientas', 'desarrollo', 'business', 'aspectos', 'uagrmbs', 'empresariales', 'postgraduantes', 'gestion', 'comercial', 'segun', 'analisis', 'ventas', 'estudio', 'horas', 'evaluacion', 'aplicar', 'santiago', 'formacion', 'realizacion', 'trabajos', 'empresas', 'santa']\n",
      "['posicionamiento', 'marketing', 'lectura', 'modulo', 'uagrmbs', 'capitulo', 'mapa', 'kotler', 'articulo', 'lecturas', 'practico', 'contenido', 'school', 'especificacion', 'empresa', 'metodologia', 'business', 'armstrong', 'gral', 'mail', 'realizacion', 'fecha', 'matriz', 'estrategias', 'calle', 'saavedra', 'basicas', 'estrategia', 'uagrm', 'requisitos']\n",
      "['marketing', 'capitulo', 'practico', 'lecturas', 'libro', 'kotler', 'uagrmbs', 'empresa', 'caso', 'armstrong', 'analisis', 'lectura', 'posicionamiento', 'contenido', 'actividades', 'basicas', 'presente', 'estrategias', 'terminar', 'estaran', 'ejercicio', 'articulo', 'analitico', 'condiciones', 'postgraduantes', 'proceso', 'plan', 'complementarias', 'gral', 'codigo']\n",
      "['modulo', 'marketing', 'business', 'uagrm', 'school', 'uagrmbs', 'fecha', 'gestion', 'santa', 'herramientas', 'empresas', 'estrategicas', 'postgraduantes', 'academicos', 'saavedra', 'solicitudes', 'mail', 'telefono', 'codigo', 'especificacion', 'realizacion', 'calle', 'requisitos', 'gral', 'analisis', 'operativo', 'comercial', 'administracion', 'estrategico', 'maestria']\n",
      "['modulo', 'contenido', 'bibliografia', 'desarrollo', 'evaluacion', 'docente', 'segun', 'participantes', 'final', 'trabajos', 'uagrmbs', 'objetivos', 'siguiente', 'medios', 'postgraduante', 'practica', 'puntos', 'teorico', 'basica', 'correspondiente', 'plataforma', 'apoyo', 'considera', 'cada', 'practicos', 'cuales', 'integrador', 'orientacion', 'estudio', 'participacion']\n",
      "['modulo', 'marketing', 'contenido', 'uagrmbs', 'school', 'segun', 'bibliografia', 'docente', 'desarrollo', 'uagrm', 'evaluacion', 'business', 'capitulo', 'fecha', 'practica', 'trabajos', 'requisitos', 'postgraduantes', 'telefono', 'lecturas', 'final', 'practico', 'mail', 'libro', 'especificacion', 'solicitudes', 'codigo', 'estudio', 'realizacion', 'calle']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(string_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = '''Describe el tema de cada una de las listas delimitadas por comillas en una oración sencilla y escribe además tres posibles subtemas diferentes. Las listas son el resultado del algoritmo \"Latent Dirichlet Allocation\" para descubrir temas.\n",
    "Utiliza el siguiente Template para la respuesta. No des una introducción ni una conclusión, solo describe los temas \n",
    "\n",
    "Tema  1: <<<(oración que describe el tema)>>>\n",
    "- <<<Frase que describe primer subtema)>>>\n",
    "- <<<(Frase que describe segundo subtema)>>>\n",
    "- <<<Frase que describe tercer subtema)>>>\n",
    "\n",
    "Tema  2: <<<(oración que describe el tema)>>>\n",
    "- <<<Frase que describe primer subtema)>>>\n",
    "- <<<(Frase que describe segundo subtema)>>>\n",
    "- <<<Frase que describe tercer subtema)>>>\n",
    "\n",
    "Listas: \"\"\"{string_lda}\"\"\" '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://ysharma-explore-llamav2-with-tgi.hf.space/ ✔\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from src import LLM_gradioAPI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define the LLM endpoint\n",
    "llm = LLM_gradioAPI(n=2000) # hugging face repo\n",
    "llm.client_api = \"https://ysharma-explore-llamav2-with-tgi.hf.space/\"\n",
    "llm.api_name = \"/chat_1\"\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "response = chain.run(string_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from src import topics_from_pdf\n",
    "from src import LLM_gradioAPI\n",
    "\n",
    "# Define the LLM endpoint\n",
    "llm = LLM_gradioAPI(n=2000) # hugging face repo\n",
    "llm.client_api = \"https://ysharma-explore-llamav2-with-tgi.hf.space/\"\n",
    "llm.api_name = \"/chat_1\"\n",
    "\n",
    "file = \"Philip Kotler, Gary Armstrong - Marketing_ Versión latinoamerica (2007).pdf\"\n",
    "file = \"PROGRAMA ANALITICO MÓDULO.pdf\"\n",
    "num_topics = 7\n",
    "words_per_topic = 30\n",
    "\n",
    "def topics_from_pdf(llm, file, num_topics, words_per_topic):\n",
    "\n",
    "    # Extract topics and convert to string\n",
    "    list_of_topicwords = get_topics_from_pdf(file, num_topics, words_per_topic)\n",
    "    string_lda = \"\"\n",
    "    for list in list_of_topicwords:\n",
    "        string_lda += str(list) + \"\\n\"\n",
    "\n",
    "    # LLM call\n",
    "    template_string = '''Describe el tema de cada una de las listas delimitadas por comillas en una oración sencilla y escribe además tres posibles subtemas diferentes. Las listas son el resultado del algoritmo \"Latent Dirichlet Allocation\" para descubrir temas.\n",
    "    Utiliza el siguiente Template para la respuesta. No des una introducción ni una conclusión, solo describe los temas \n",
    "\n",
    "    Tema  1: <<<(oración que describe el tema)>>>\n",
    "    - <<<Frase que describe primer subtema)>>>\n",
    "    - <<<(Frase que describe segundo subtema)>>>\n",
    "    - <<<Frase que describe tercer subtema)>>>\n",
    "\n",
    "    Tema  2: <<<(oración que describe el tema)>>>\n",
    "    - <<<Frase que describe primer subtema)>>>\n",
    "    - <<<(Frase que describe segundo subtema)>>>\n",
    "    - <<<Frase que describe tercer subtema)>>>\n",
    "\n",
    "    Listas: \"\"\"{string_lda}\"\"\" '''\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    response = chain.run(string_lda)\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton_glfk00f\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://ysharma-explore-llamav2-with-tgi.hf.space/ ✔\n"
     ]
    }
   ],
   "source": [
    "from src import LLM_gradioAPI\n",
    "from src import topics_from_pdf\n",
    "import openai\n",
    "\n",
    "# Define the LLM endpoint\n",
    "llm = LLM_gradioAPI(n=2000) # hugging face repo\n",
    "llm.client_api = \"https://ysharma-explore-llamav2-with-tgi.hf.space/\"\n",
    "llm.api_name = \"/chat_1\"\n",
    "\n",
    "# import os\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv())\n",
    "# openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "# llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "#file = \"Philip Kotler, Gary Armstrong - Marketing_ Versión latinoamerica (2007).pdf\"\n",
    "#file = \"PROGRAMA ANALITICO MÓDULO.pdf\"\n",
    "file = \"Philip Kotler, Gary Armstrong, Sridhar Balasubramanian - Principles of Marketing-Pearson (2023).pdf\"\n",
    "\n",
    "num_topics = 3\n",
    "words_per_topic = 30 # optimizar\n",
    "\n",
    "topics = topics_from_pdf(llm, file, num_topics, words_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tema 1: Marketing\n",
      "\n",
      "* Subtema 1: Estrategias de marketing\n",
      "* Subtema 2: Publicidad y promoción\n",
      "* Subtema 3: Análisis de mercado y consumidores\n",
      "\n",
      "Tema 2: Branding\n",
      "\n",
      "* Subtema 1: Desarrollo y gestión de la marca\n",
      "* Subtema 2: Comunicación y promoción de la marca\n",
      "* Subtema 3: Evaluación y medición del éxito de la marca\n",
      "\n",
      "Tema 3: Ventas y comercio\n",
      "\n",
      "* Subtema 1: Estrategias de ventas y comercialización\n",
      "* Subtema 2: Gestión de relaciones con clientes (CRM)\n",
      "* Subtema 3: Análisis de tendencias y resultados de ventas\n",
      "\n",
      "Es importante destacar que estos temas y subtemas son solo una posible interpretación de los datos proporcionados y que pueden variar dependiendo del contexto y la perspectiva de cada persona.\n"
     ]
    }
   ],
   "source": [
    "print(topics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_app_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
